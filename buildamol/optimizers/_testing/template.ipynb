{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook template is designed for testing the performance of Rotatron environments and different solving agents of different scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Work on local biobuild in GIT repo\n",
    "# =============================================================================\n",
    "import os, sys, importlib\n",
    "\n",
    "# for inside python scripts\n",
    "# base = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))\n",
    "base = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "sys.path.insert(0, base)\n",
    "\n",
    "def reload_optimizers():\n",
    "    importlib.reload(bam.optimizers.environments)\n",
    "    importlib.reload(bam.optimizers.agents)\n",
    "# =============================================================================\n",
    "import files\n",
    "import auxiliary\n",
    "import buildamol as bam\n",
    "import buildamol.optimizers.environments as envs\n",
    "import buildamol.optimizers.agents as agents\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can select which tests to run and on what testing structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which structures to run on\n",
    "structures_to_run_on = [\n",
    "    files.GLUCOSE2,\n",
    "    # files.PEPTIDE,\n",
    "    # files.X_WING,\n",
    "    # files.X_WING2,\n",
    "    # files.SCAFFOLD1,\n",
    "    # files.SCAFFOLD3,\n",
    "]\n",
    "\n",
    "# how many times to independently run on each structure\n",
    "re_runs = 1\n",
    "\n",
    "# visualize evaluation history\n",
    "visualize_eval_history = True\n",
    "\n",
    "# visualize time history\n",
    "visualize_time_history = True\n",
    "\n",
    "# visualise clashes in final structure\n",
    "visualize_clashes = True\n",
    "\n",
    "# clash threshold\n",
    "clash_cutoff = 0.5\n",
    "\n",
    "# visualize the final structure\n",
    "visualize_final_structure = True\n",
    "\n",
    "# visualization parameters\n",
    "# for draw_edges()\n",
    "visualization_params = dict(color=\"magenta\", opacity=0.3)\n",
    "\n",
    "# export visualization to html\n",
    "export_visualization = True\n",
    "\n",
    "# export solutions as PDB\n",
    "export_pdb = True\n",
    "\n",
    "# export history to csv\n",
    "export_history = True\n",
    "\n",
    "# export name prefix\n",
    "export_name_prefix = None\n",
    "\n",
    "# graph building function\n",
    "# provide a custom callable that generates a tuple of (graph, rotatable_edges)\n",
    "graph_factory = None\n",
    "\n",
    "# graph building parameters\n",
    "graph_params = {}\n",
    "\n",
    "# provide a custom callable to set a custom building function for the environment\n",
    "rotatron_factory = None\n",
    "\n",
    "# the rotatron class to use\n",
    "rotatron_class = None\n",
    "\n",
    "# rotatron parameters\n",
    "rotatron_params = {}\n",
    "\n",
    "# the agent function to use\n",
    "agent = None\n",
    "\n",
    "# agent parameters\n",
    "agent_params = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform some environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if agent is None:\n",
    "    raise ValueError(\"No agent provided\")\n",
    "if rotatron_class is None:\n",
    "    raise ValueError(\"No rotatron class provided\")\n",
    "    \n",
    "if graph_factory is None:\n",
    "    graph_factory = auxiliary.graph_factory\n",
    "if rotatron_factory is None:\n",
    "    rotatron_factory = auxiliary.rotatron_factory\n",
    "\n",
    "available_structures = {}\n",
    "\n",
    "eval_history = defaultdict(list)\n",
    "time_history = defaultdict(list)\n",
    "clash_history = defaultdict(list)\n",
    "final_visuals = {}\n",
    "initial_evals = {}\n",
    "initial_clashes = {}\n",
    "v = None\n",
    "\n",
    "if not export_name_prefix:\n",
    "    export_name_prefix = rotatron_class.__name__ + \".\" + agent.__name__\n",
    "\n",
    "\n",
    "def make_environment(structure):\n",
    "    \"\"\"\n",
    "    An environment generator\n",
    "    \"\"\"\n",
    "    graph, rotatable_edges = graph_factory(structure, **graph_params)\n",
    "    return rotatron_factory(rotatron_class, graph, rotatable_edges, **rotatron_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now start the main testing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for structure in structures_to_run_on:\n",
    "    print(f\"Running on {structure}\")\n",
    "    if structure not in available_structures:\n",
    "        s = bam.molecule(structure)\n",
    "        available_structures[structure] = s\n",
    "        \n",
    "    structure = available_structures[structure]\n",
    "    env = make_environment(structure)\n",
    "    initial_evals[structure.id] = [env._best_eval] * re_runs\n",
    "    initial_clashes[structure.id] = [auxiliary.compute_clashes(env.state, clash_cutoff)] * re_runs\n",
    "    \n",
    "    if visualize_final_structure:\n",
    "        if not v:\n",
    "            v = structure.draw()\n",
    "            v.draw_edges(*env.rotatable_edges, color=\"cyan\", linewidth=6)\n",
    "\n",
    "    for r in range(re_runs):\n",
    "        t1 = time.time()\n",
    "        # we are interested in learning the full time to make and solve the environment\n",
    "        env = make_environment(structure)\n",
    "        sol, eval = agent(env, **agent_params)\n",
    "        t2 = time.time()\n",
    "        eval_history[structure.id].append(eval)\n",
    "        time_history[structure.id].append(t2 - t1)\n",
    "        clash_history[structure.id].append(auxiliary.compute_clashes(env.state, clash_cutoff))\n",
    "        if visualize_final_structure:\n",
    "            final = auxiliary.apply_solution(sol, env, structure.copy())\n",
    "            v.draw_edges(*final.bonds, **visualization_params)        \n",
    "        \n",
    "        if export_pdb:\n",
    "            sol = auxiliary.apply_solution(sol, env, structure.copy())\n",
    "            sol.to_pdb(f\"{export_name_prefix}.{structure.id}_{r}.pdb\")  \n",
    "          \n",
    "        env.reset()\n",
    "        print(f\"Run {r+1}/{re_runs} complete ({t2 - t1:.2f}s)\")\n",
    "    \n",
    "    if visualize_final_structure:\n",
    "        _best = auxiliary.apply_solution(env.best[1], env, structure.copy())\n",
    "        if export_pdb:\n",
    "            _best.to_pdb(f\"{export_name_prefix}.{structure.id}_best.pdb\")\n",
    "        v.draw_edges(*_best.bonds, color=\"green\", linewidth=6)\n",
    "        final_visuals[structure.id] = v\n",
    "        v = None    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now do some data collecting and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_eval_history = auxiliary.transform_to_df(\n",
    "    eval_history, initial_evals, \"final\", \"initial\"\n",
    ")\n",
    "_clash_history = auxiliary.transform_to_df(\n",
    "    clash_history, initial_clashes, \"final\", \"initial\"\n",
    ")\n",
    "_time_history = auxiliary.transform_to_df(time_history)\n",
    "\n",
    "if export_history:\n",
    "    \n",
    "    _eval_history.to_csv(f\"{export_name_prefix}.eval_history.csv\", index=False)\n",
    "    _time_history.to_csv(f\"{export_name_prefix}.time_history.csv\", index=False)\n",
    "    _clash_history.to_csv(f\"{export_name_prefix}.clash_history.csv\", index=False)\n",
    "\n",
    "if visualize_eval_history or visualize_time_history or visualize_clashes:\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 3))\n",
    "    if visualize_eval_history:\n",
    "        _df = _eval_history.melt(id_vars=\"key\", value_vars=[\"final\", \"initial\"], var_name=\"type\", value_name=\"eval\")\n",
    "        sns.barplot(data=_df, ax=axs[0], x=\"key\", y=\"eval\", hue=\"type\")\n",
    "        axs[0].set(title=\"Evaluation of finals\", ylabel=\"eval-score\", xlabel=\"\")\n",
    "        axs[0].legend().set_visible(False)\n",
    "        \n",
    "    if visualize_time_history:\n",
    "        sns.barplot(data=_time_history, ax=axs[1], x=\"key\", y=0)\n",
    "        axs[1].set(title=\"Computation times\", ylabel=\"seconds\", xlabel=\"\")\n",
    "\n",
    "    if visualize_clashes:\n",
    "        # _clash_history[\"diff\"] = _clash_history[\"final\"] - _clash_history[\"initial\"]\n",
    "        _df = _clash_history.melt(id_vars=\"key\", value_vars=[\"final\", \"initial\"], var_name=\"type\", value_name=\"clashes\")\n",
    "        sns.barplot(data=_df, ax=axs[2], x=\"key\", y=\"clashes\", hue=\"type\")\n",
    "        axs[2].set(title=\"Clashes in finals\", xlabel=\"\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    fig.supxlabel(f\"{rotatron_class.__name__} + {agent.__name__}\")\n",
    "    plt.savefig(f\"{export_name_prefix}.plots.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here can the 3d visualizations be viewed then \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GL2': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if export_visualization and export_visualization:\n",
    "    if not export_name_prefix:\n",
    "        export_name_prefix = rotatron_class.__name__ + \".\" + agent.__name__\n",
    "    for structure_id, v in final_visuals.items():\n",
    "        if v:\n",
    "            v.figure.write_html(f\"{export_name_prefix}.{structure_id}.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glyco2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
